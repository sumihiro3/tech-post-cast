import { AppConfigService } from '@/app-config/app-config.service';
import { TextToSpeechError } from '@/types/errors';
import { IProgramFileMaker } from '@domains/radio-program/program-file-maker.interface';
import { google } from '@google-cloud/text-to-speech/build/protos/protos';
import { TermsRepository } from '@infrastructure/database/terms/terms.repository';
import { Test, TestingModule } from '@nestjs/testing';
import * as fs from 'fs';
import { MockFunctionMetadata, ModuleMocker } from 'jest-mock';
import { setTimeout } from 'timers/promises';
import { TextToSpeechClient } from './text-to-speech';

const moduleMocker = new ModuleMocker(global);

jest.mock('@google-cloud/text-to-speech');
jest.mock('fs');
jest.mock('timers/promises');

describe('TextToSpeechClient', () => {
  let textToSpeechClient: TextToSpeechClient;
  let appConfigService: AppConfigService;
  let termsRepository: TermsRepository;
  let programFileMaker: IProgramFileMaker;
  let ttsClientMock: any;

  beforeEach(async () => {
    const module: TestingModule = await Test.createTestingModule({
      providers: [TextToSpeechClient],
    })
      .useMocker((token) => {
        if (token === AppConfigService) {
          return {};
        } else if (token === TermsRepository) {
          return {};
        } else if (token === 'ProgramFileMaker') {
          return {
            mergeAudioFilesSegments: jest.fn(),
          };
        }
        if (typeof token === 'function') {
          const mockMetadata = moduleMocker.getMetadata(
            token,
          ) as MockFunctionMetadata<any, any>;
          const Mock = moduleMocker.generateFromMetadata(mockMetadata);
          return new Mock();
        }
      })
      .compile();
    ttsClientMock = {
      synthesizeSpeech: jest.fn(),
    };
    textToSpeechClient = module.get<TextToSpeechClient>(TextToSpeechClient);
    textToSpeechClient['ttsClient'] = ttsClientMock;

    appConfigService = module.get<AppConfigService>(AppConfigService);
    termsRepository = module.get<TermsRepository>(TermsRepository);
    programFileMaker = module.get('ProgramFileMaker');
  });

  it('should be defined', () => {
    expect(textToSpeechClient).toBeDefined();
    expect(appConfigService).toBeDefined();
    expect(termsRepository).toBeDefined();
    expect(programFileMaker).toBeDefined();
  });

  describe('synthesizeSpeech', () => {
    test('éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ­£å¸¸ã«ç”Ÿæˆã™ã‚‹', async () => {
      // arrange
      const request: google.cloud.texttospeech.v1.ISynthesizeSpeechRequest = {
        input: { ssml: '<speak>Hello</speak>' },
        voice: { languageCode: 'en-US', name: 'en-US-Wavenet-D' },
        audioConfig: { audioEncoding: 'MP3' },
      };
      const outputFilePath = 'output.mp3';
      const audioContent = 'audioContent';
      ttsClientMock.synthesizeSpeech.mockResolvedValue([{ audioContent }]);
      jest.spyOn(fs, 'writeFileSync').mockImplementation(jest.fn());
      jest.spyOn(global, 'setTimeout').mockImplementation(jest.fn());

      // act
      await textToSpeechClient.synthesizeSpeech(request, outputFilePath);

      // assert
      expect(ttsClientMock.synthesizeSpeech).toHaveBeenCalledWith(request);
      expect(fs.writeFileSync).toHaveBeenCalledWith(
        outputFilePath,
        audioContent,
        'binary',
      );
      expect(setTimeout).toHaveBeenCalledWith(1000);
    });

    test('éŸ³å£°ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒãªã„å ´åˆã«ã‚¨ãƒ©ãƒ¼ã‚’ã‚¹ãƒ­ãƒ¼ã™ã‚‹', async () => {
      // arrange
      const request: google.cloud.texttospeech.v1.ISynthesizeSpeechRequest = {
        input: { ssml: '<speak>Hello</speak>' },
        voice: { languageCode: 'en-US', name: 'en-US-Wavenet-D' },
        audioConfig: { audioEncoding: 'MP3' },
      };
      const outputFilePath = 'output.mp3';
      ttsClientMock.synthesizeSpeech.mockResolvedValue([{}]);

      // act & assert
      await expect(
        textToSpeechClient.synthesizeSpeech(request, outputFilePath),
      ).rejects.toThrow(TextToSpeechError);
    });

    test('ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã« TextToSpeechError ã‚’ã‚¹ãƒ­ãƒ¼ã™ã‚‹', async () => {
      // arrange
      const request: google.cloud.texttospeech.v1.ISynthesizeSpeechRequest = {
        input: { ssml: '<speak>Hello</speak>' },
        voice: { languageCode: 'en-US', name: 'en-US-Wavenet-D' },
        audioConfig: { audioEncoding: 'MP3' },
      };
      const outputFilePath = 'output.mp3';
      const error = new Error('error');
      ttsClientMock.synthesizeSpeech.mockRejectedValue(error);

      // act & assert
      await expect(
        textToSpeechClient.synthesizeSpeech(request, outputFilePath),
      ).rejects.toThrow(TextToSpeechError);
    });
  });

  describe('generateTextToSpeechRequest', () => {
    test('Text to speech ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹', () => {
      // arrange
      const ssml = '<speak>Hello</speak>';

      // act
      const request = textToSpeechClient.generateTextToSpeechRequest(ssml);

      // assert
      expect(request).toEqual({
        input: { ssml },
        voice: { languageCode: 'ja-JP', name: 'ja-JP-Wavenet-B' },
        audioConfig: {
          audioEncoding: 'MP3',
          effectsProfileId: ['handset-class-device'],
          pitch: -5.0,
          speakingRate: 1.1,
        },
      });
    });
  });

  describe('removeEmoji', () => {
    test('æ–‡å­—åˆ—ã‹ã‚‰çµµæ–‡å­—ã‚’å‰Šé™¤ã™ã‚‹', () => {
      // arrange
      const text = 'Hello ğŸ˜Š';

      // act
      const result = textToSpeechClient.removeEmoji(text);

      // assert
      expect(result).toBe('Hello ');
    });
  });

  describe('formatAudioText', () => {
    test('éŸ³å£°ãƒ†ã‚­ã‚¹ãƒˆã‚’æ•´å½¢ã™ã‚‹', async () => {
      // arrange
      const text = `<Helloã€‚ termï¼ï¼Ÿ>""'&&&`;
      const term = { term: 'term', reading: 'reading' };
      const terms = [term];
      textToSpeechClient.getTerms = jest.fn().mockResolvedValue(terms);

      // act
      const result = await textToSpeechClient.formatAudioText(text);

      // assert
      const formattedText = `&lt;Helloã€‚<break time="600ms"/> <sub alias="${term.reading}">${term.term}</sub> ï¼<break time="600ms"/>ï¼Ÿ<break time="600ms"/>&gt;&quot;&quot;&apos;&amp;&amp;&amp;`;
      expect(result).toBe(formattedText);
      expect(textToSpeechClient.getTerms).toHaveBeenCalledTimes(1);
    });
  });

  describe('getTerms', () => {
    test('ãƒªãƒã‚¸ãƒˆãƒªã‹ã‚‰ç”¨èªã‚’å–å¾—ã™ã‚‹', async () => {
      // arrange
      const terms = [{ term: 'term', reading: 'reading' }];
      termsRepository.find = jest.fn().mockResolvedValue(terms);

      // act
      const result = await textToSpeechClient.getTerms();

      // assert
      expect(result).toBe(terms);
    });
  });

  describe('splitJapaneseTextBySentence', () => {
    test('æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã‚’æ–‡å˜ä½ã§åˆ†å‰²ã™ã‚‹', () => {
      // arrange
      const text = 'æœ€åˆã®æ–‡ã§ã™ã€‚2ç•ªç›®ã®æ–‡ã§ã™ã€‚3ç•ªç›®ã®æ–‡ã§ã™ã€‚';

      // act
      const result = (textToSpeechClient as any).splitJapaneseTextBySentence(
        text,
      );

      // assert
      // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®maxLength=1000ã§åˆ†å‰²ã™ã‚‹ã¨æ–‡ãŒçŸ­ã„ãŸã‚1ã¤ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã«ãªã‚‹
      expect(result).toEqual(['æœ€åˆã®æ–‡ã§ã™ã€‚2ç•ªç›®ã®æ–‡ã§ã™ã€‚3ç•ªç›®ã®æ–‡ã§ã™ã€‚']);
    });

    test('æœ€å¤§é•·ã‚’è¶…ãˆã‚‹å ´åˆã¯è¤‡æ•°ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã«åˆ†å‰²ã™ã‚‹', () => {
      // arrange
      const text = 'æœ€åˆã®æ–‡ã§ã™ã€‚2ç•ªç›®ã®æ–‡ã§ã™ã€‚3ç•ªç›®ã®æ–‡ã§ã™ã€‚';
      const maxLength = 10;
      const expectedSegmentLength = 3;

      // act
      const result = (textToSpeechClient as any).splitJapaneseTextBySentence(
        text,
        maxLength,
      );

      // assert
      expect(result.length).toBe(expectedSegmentLength);
    });

    test('æ–‡ã®åˆ†å‰²ãŒæ­£ã—ãè¡Œã‚ã‚Œã‚‹', () => {
      // arrange
      const text = 'æœ€åˆã®æ–‡ã§ã™ã€‚2ç•ªç›®ã®æ–‡ã§ã™ã€‚3ç•ªç›®ã®æ–‡ã§ã™ã€‚';

      // act
      // å†…éƒ¨å®Ÿè£…ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦æ–‡ã®åˆ†å‰²éƒ¨åˆ†ã ã‘ã‚’ãƒ†ã‚¹ãƒˆ
      const sentences = text.split(/(?<=ã€‚)/);

      // assert
      expect(sentences).toEqual([
        'æœ€åˆã®æ–‡ã§ã™ã€‚',
        '2ç•ªç›®ã®æ–‡ã§ã™ã€‚',
        '3ç•ªç›®ã®æ–‡ã§ã™ã€‚',
      ]);
    });
  });
});
